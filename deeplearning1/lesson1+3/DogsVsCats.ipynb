{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning can be used to use a pre-trained to learn new classes. The lesson uses networks trained on ImageNet to learn a new classifier to predict if an image is a dog or a cat\n",
    "\n",
    "This notebook uses the previously generated TFRecords for data and the VGG16 model as a base to learn new classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the directories into TFRecords in the DataPreparation.ipynb previously so will use them as our data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser('~/data/DogsVsCats')\n",
    "\n",
    "dev_data_dir = os.path.join(data_dir, 'dev')\n",
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "test_data_dir = os.path.join(data_dir, 'test1')\n",
    "validation_data_dir = os.path.join(data_dir, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev dataset contains only 10 images and is useful for ensuring network runs correctly. Handy to not have to wait a long time while testing the network and can switch to train and validation once entire architecture is ensured to work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_record_filenames = os.path.join(data_dir, 'dev.tfrecord')\n",
    "train_record_filenames = glob.glob(os.path.join(data_dir, 'train-*.tfrecord'))\n",
    "validation_record_filenames = glob.glob(os.path.join(data_dir, 'validation-*.tfrecord'))\n",
    "test_record_filenames = os.path.join(data_dir, 'test.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries to map from integer label and string label for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'class_name2id.p'), 'rb') as p:\n",
    "    class_name2id = pickle.load(p)\n",
    "id2class = {v:k for v, k in enumerate(class_name2id)}\n",
    "NUM_CLASSES = len(id2class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to construct out data `input_fn` methods to be used later when passed to the `Experiment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lesson 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_input_fn(filenames, num_epochs=1, batch_size=64, shuffle=False):\n",
    "    \n",
    "    def _input_fn():\n",
    "        def _parse_record(tf_record):\n",
    "            features = {\n",
    "                'image': tf.FixedLenFeature([], dtype=tf.string),\n",
    "                'label': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "            }\n",
    "            record = tf.parse_single_example(tf_record, features)\n",
    "\n",
    "            image_raw = tf.decode_raw(record['image'], tf.float32)\n",
    "            image_raw = tf.reshape(image_raw, shape=(224, 224, 3))\n",
    "\n",
    "            label = tf.cast(record['label'], tf.int32)\n",
    "            label = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "\n",
    "            return { 'image': image_raw }, label\n",
    "        \n",
    "        # For TF dataset blog post, see https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html\n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "        dataset = dataset.map(_parse_record)\n",
    "\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=256)\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16_model_fn(features, mode, params):\n",
    "    \n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    with tf.name_scope('vgg_base'):\n",
    "        # Use a pre-trained VGG16 model and drop off the top layers as we will retrain \n",
    "        # with our own dense output for our custom classes\n",
    "        vgg16_base = tf.keras.applications.VGG16(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            input_tensor=features['image'],\n",
    "            pooling='avg')\n",
    "\n",
    "        # Disable training for all layers to increase speed for transfer learning\n",
    "        # If new classes significantely different from ImageNet, this may be worth leaving as trainable = True\n",
    "        for layer in vgg16_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        x = vgg16_base.output\n",
    "    \n",
    "    with tf.variable_scope(\"fc\"):\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, units=4096, activation=tf.nn.relu, trainable=is_training, name='fc1')\n",
    "        x = tf.layers.dense(x, units=4096, activation=tf.nn.relu, trainable=is_training, name='fc2')\n",
    "        x = tf.layers.dropout(x, rate=0.5, training=is_training)\n",
    "        \n",
    "    # Finally add a 2 dense layer for class predictions\n",
    "    with tf.variable_scope(\"Prediction\"):\n",
    "        x = tf.layers.dense(x, units=NUM_CLASSES, trainable=is_training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    tf.summary.image('images', features['image'], max_outputs=6)\n",
    "    \n",
    "    logits = vgg16_model_fn(features, mode, params)\n",
    "    \n",
    "    # Dictionary with label as outcome with greatest probability\n",
    "    # Softmax will provide probabilities of each label\n",
    "    predictions = {\n",
    "        'class': tf.argmax(logits, axis=1, output_type=tf.int32),\n",
    "        'probabilities': tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    # Return our EstimatorSpec for predict mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # A tensor so the graph can access the string label for the class given it's integer index label\n",
    "#         class_tensor = tf.constant([id2class[label] for label in range(NUM_CLASSES)])\n",
    "        \n",
    "#         export_outputs = {\n",
    "#             'predict_output': tf.estimator.export.ClassificationOutput(\n",
    "#                 scores=scores,\n",
    "#                 classes=tf.contrib.lookup.index_to_string(predicted_class, mapping=class_tensor, default_value='UNKNOWN')\n",
    "#             )\n",
    "#         }\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions\n",
    "        )\n",
    "\n",
    "    # Softmax loss\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=tf.argmax(labels, axis=1),\n",
    "        predictions=predictions['class'],\n",
    "        name='accuracy'\n",
    "    )\n",
    "    \n",
    "    # Return the EstimatorSpec for training mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=params['learning_rate'],\n",
    "            optimizer=tf.train.AdamOptimizer\n",
    "        )\n",
    "        \n",
    "        tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "            loss=loss,\n",
    "            train_op=train_op\n",
    "        )\n",
    "    \n",
    "    assert mode == tf.estimator.ModeKeys.EVAL\n",
    "    \n",
    "    # Setup evaluation metrics\n",
    "    eval_metrics = { 'accuracy': accuracy }\n",
    "    \n",
    "    # Return EstimatorSpec for evaluation mode\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        eval_metric_ops=eval_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 2e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/DogsVsCats', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1172a6080>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# run_config = tf.contrib.learn.RunConfig()\n",
    "# run_config = run_config.replace(model_dir='/tmp/DogsVsCats')\n",
    "\n",
    "run_config = tf.estimator.RunConfig(model_dir='/tmp/DogsVsCats')\n",
    "\n",
    "dog_cat_estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_fn = data_input_fn(train_record_filenames, num_epochs=None, batch_size=10, shuffle=True)\n",
    "eval_input_fn = data_input_fn(validation_record_filenames, batch_size=1)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=train_input_fn, \n",
    "    max_steps=12)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=eval_input_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/DogsVsCats/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.69353, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 12 into /tmp/DogsVsCats/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1172a67b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_cat_estimator.train(input_fn=train_input_fn, max_steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get an error about tensor not an element of the graph. See GitHub issue https://github.com/tensorflow/tensorflow/issues/14356\n",
    "# Only solution to clear session so keras reloads between runs...\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-18-11:21:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/DogsVsCats/model.ckpt-12\n",
      "INFO:tensorflow:Evaluation [1/2]\n",
      "INFO:tensorflow:Evaluation [2/2]\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-18-11:22:00\n",
      "INFO:tensorflow:Saving dict for global step 12: accuracy = 1.0, global_step = 12, loss = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0, 'global_step': 12, 'loss': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_cat_estimator.evaluate(input_fn=eval_input_fn, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Running train works, but when continues to evaluate gets error as raised by \n",
    "# GitHub issue above, hence separate train and then evaluate call\n",
    "# tf.estimator.train_and_evaluate(dog_cat_estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_spec = {\n",
    "    'image': tf.placeholder(tf.float32, shape=(None, 224, 224, 3))\n",
    "}\n",
    "input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec)\n",
    "\n",
    "dog_cat_estimator.export_savedmodel(\n",
    "    export_dir_base='/tmp/DogsVsCatsExport',\n",
    "    serving_input_receiver_fn=input_receiver_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# lesson 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation of image set. Try augmentation within `input_fn` via operations available in [`tf.image`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/image) such as\n",
    "* `random_flip_lef_right` \n",
    "* `random_flip_up_down`\n",
    "* random rotation\n",
    "* random skew\n",
    "\n",
    "Also to try add Batch Normalization to input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_augmentation_input_fn(filenames, num_epochs=1, batch_size=64, shuffle=False):\n",
    "    \n",
    "    def _input_fn():\n",
    "        def _parse_record(tf_record):\n",
    "            features = {\n",
    "                'image': tf.FixedLenFeature([], dtype=tf.string),\n",
    "                'label': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "            }\n",
    "            record = tf.parse_single_example(tf_record, features)\n",
    "\n",
    "            image_raw = tf.decode_raw(record['image'], tf.float32)\n",
    "            image_raw = tf.reshape(image_raw, shape=(224, 224, 3))\n",
    "            \n",
    "            # Data augmentation\n",
    "            image_raw = tf.image.random_flip_left_right(image_raw)\n",
    "            # fastai also does random rotation, width/height shift, shear, zoom\n",
    "\n",
    "            label = tf.cast(record['label'], tf.int32)\n",
    "            label = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "\n",
    "            return { 'image': image_raw }, label\n",
    "        \n",
    "        # For TF dataset blog post, see https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html\n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "        dataset = dataset.map(_parse_record)\n",
    "\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=256)\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
