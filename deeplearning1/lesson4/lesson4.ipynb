{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = os.path.expanduser('~/data/fastai/lesson4')\n",
    "model_path = '/tmp/fastai/lesson4'\n",
    "\n",
    "if not os.path.isdir(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "if not os.path.isdir(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    \n",
    "movielens_folder = os.path.join(data_directory, 'ml-latest-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset if we don't have it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fallback_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "if not os.path.isdir(movielens_folder):\n",
    "    local_zip_path = os.path.join(data_directory, os.path.basename(fallback_url))\n",
    "    if not os.path.isfile(local_zip_path):\n",
    "        # Download zip file\n",
    "        urllib.request.urlretrieve(fallback_url, local_zip_path)\n",
    "    # Unzip file\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as z:\n",
    "        z.extractall(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1       31     2.5\n",
       "1       1     1029     3.0\n",
       "2       1     1061     3.0\n",
       "3       1     1129     2.0\n",
       "4       1     1172     4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_path = os.path.join(movielens_folder, 'ratings.csv')\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "ratings = ratings.drop(['timestamp'], axis=1)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_path = os.path.join(movielens_folder, 'movies.csv')\n",
    "movie_names = pd.read_csv(movies_path, index_col='movieId')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ratings['userId'].unique()\n",
    "movies = ratings['movieId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid2idx = { userId: index for index, userId in enumerate(users) }\n",
    "movieid2idx = { movieId: index for index, movieId in enumerate(movies) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: write index to user and movie label metadata to model folder for tensorboard to use and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update movie and user Ids in ratings to be the index so we have a contiguous integer range for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings['userId'] = ratings['userId'].apply(userid2idx.get)\n",
    "ratings['movieId'] = ratings['movieId'].apply(movieid2idx.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        0     2.5\n",
       "1       0        1     3.0\n",
       "2       0        2     3.0\n",
       "3       0        3     2.0\n",
       "4       0        4     4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0-rc1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ratings[['userId', 'movieId']]\n",
    "y = ratings['rating']\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(x, y=y, target_column='rating', shuffle=True, num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=tf.feature_column.categorical_column_with_identity('userId', num_buckets=len(users), default_value=0), \n",
    "    dimension=50)\n",
    "movie_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=tf.feature_column.categorical_column_with_identity('movieId', num_buckets=len(movies), default_value=0), \n",
    "    dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/fastai/lesson4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12103be48>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [user_embedding, movie_embedding]\n",
    "estimator = tf.estimator.DNNRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[70], \n",
    "    dropout=0.75,\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\n",
    "    model_dir=model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/fastai/lesson4/model.ckpt-6251\n",
      "INFO:tensorflow:Saving checkpoints for 6252 into /tmp/fastai/lesson4/model.ckpt.\n",
      "INFO:tensorflow:loss = 67.1762, step = 6252\n",
      "INFO:tensorflow:global_step/sec: 209.879\n",
      "INFO:tensorflow:loss = 141.99, step = 6352 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.541\n",
      "INFO:tensorflow:loss = 88.3842, step = 6452 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.15\n",
      "INFO:tensorflow:loss = 148.684, step = 6552 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.923\n",
      "INFO:tensorflow:loss = 56.9887, step = 6652 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.597\n",
      "INFO:tensorflow:loss = 90.7707, step = 6752 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.052\n",
      "INFO:tensorflow:loss = 77.5105, step = 6852 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.005\n",
      "INFO:tensorflow:loss = 91.5582, step = 6952 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.168\n",
      "INFO:tensorflow:loss = 78.4077, step = 7052 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.213\n",
      "INFO:tensorflow:loss = 85.8754, step = 7152 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.559\n",
      "INFO:tensorflow:loss = 92.3546, step = 7252 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.319\n",
      "INFO:tensorflow:loss = 82.7003, step = 7352 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.355\n",
      "INFO:tensorflow:loss = 94.9726, step = 7452 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.304\n",
      "INFO:tensorflow:loss = 117.415, step = 7552 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.454\n",
      "INFO:tensorflow:loss = 90.2517, step = 7652 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.987\n",
      "INFO:tensorflow:loss = 119.185, step = 7752 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.392\n",
      "INFO:tensorflow:loss = 86.4564, step = 7852 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.241\n",
      "INFO:tensorflow:loss = 74.6631, step = 7952 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.387\n",
      "INFO:tensorflow:loss = 86.3887, step = 8052 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.637\n",
      "INFO:tensorflow:loss = 106.569, step = 8152 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.985\n",
      "INFO:tensorflow:loss = 119.674, step = 8252 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.071\n",
      "INFO:tensorflow:loss = 66.627, step = 8352 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.356\n",
      "INFO:tensorflow:loss = 101.802, step = 8452 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.593\n",
      "INFO:tensorflow:loss = 103.801, step = 8552 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.829\n",
      "INFO:tensorflow:loss = 96.0913, step = 8652 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.897\n",
      "INFO:tensorflow:loss = 110.044, step = 8752 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.657\n",
      "INFO:tensorflow:loss = 50.7385, step = 8852 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.726\n",
      "INFO:tensorflow:loss = 93.8651, step = 8952 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.941\n",
      "INFO:tensorflow:loss = 87.9628, step = 9052 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.667\n",
      "INFO:tensorflow:loss = 112.708, step = 9152 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.196\n",
      "INFO:tensorflow:loss = 109.888, step = 9252 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.183\n",
      "INFO:tensorflow:loss = 79.0308, step = 9352 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.334\n",
      "INFO:tensorflow:loss = 94.0361, step = 9452 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.584\n",
      "INFO:tensorflow:loss = 104.986, step = 9552 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.725\n",
      "INFO:tensorflow:loss = 73.6702, step = 9652 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.151\n",
      "INFO:tensorflow:loss = 74.3596, step = 9752 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.664\n",
      "INFO:tensorflow:loss = 94.0688, step = 9852 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.541\n",
      "INFO:tensorflow:loss = 88.257, step = 9952 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.377\n",
      "INFO:tensorflow:loss = 103.003, step = 10052 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.678\n",
      "INFO:tensorflow:loss = 101.519, step = 10152 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.603\n",
      "INFO:tensorflow:loss = 97.743, step = 10252 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.704\n",
      "INFO:tensorflow:loss = 73.1292, step = 10352 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.265\n",
      "INFO:tensorflow:loss = 164.736, step = 10452 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.59\n",
      "INFO:tensorflow:loss = 99.11, step = 10552 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.552\n",
      "INFO:tensorflow:loss = 119.075, step = 10652 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.416\n",
      "INFO:tensorflow:loss = 61.7253, step = 10752 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.647\n",
      "INFO:tensorflow:loss = 70.1298, step = 10852 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.788\n",
      "INFO:tensorflow:loss = 46.6253, step = 10952 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.597\n",
      "INFO:tensorflow:loss = 112.802, step = 11052 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.52\n",
      "INFO:tensorflow:loss = 86.0647, step = 11152 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.101\n",
      "INFO:tensorflow:loss = 92.6301, step = 11252 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.545\n",
      "INFO:tensorflow:loss = 92.6269, step = 11352 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.506\n",
      "INFO:tensorflow:loss = 87.6957, step = 11452 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.67\n",
      "INFO:tensorflow:loss = 95.8773, step = 11552 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.232\n",
      "INFO:tensorflow:loss = 105.834, step = 11652 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.03\n",
      "INFO:tensorflow:loss = 83.2587, step = 11752 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.43\n",
      "INFO:tensorflow:loss = 70.0732, step = 11852 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.315\n",
      "INFO:tensorflow:loss = 93.1996, step = 11952 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.308\n",
      "INFO:tensorflow:loss = 56.8862, step = 12052 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.414\n",
      "INFO:tensorflow:loss = 107.792, step = 12152 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.844\n",
      "INFO:tensorflow:loss = 90.2395, step = 12252 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.059\n",
      "INFO:tensorflow:loss = 78.1934, step = 12352 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.365\n",
      "INFO:tensorflow:loss = 80.8948, step = 12452 (0.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12502 into /tmp/fastai/lesson4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 34.5487.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x12103bac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-10-31-06:38:29\n",
      "INFO:tensorflow:Restoring parameters from /tmp/fastai/lesson4/model.ckpt-12502\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-31-06:38:39\n",
      "INFO:tensorflow:Saving dict for global step 12502: average_loss = 0.623869, global_step = 12502, loss = 79.8457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 0.62386942, 'global_step': 12502, 'loss': 79.845703}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x, y=y, target_column='rating', shuffle=False, num_epochs=1)\n",
    "estimator.evaluate(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/fastai/lesson4/model.ckpt-12502\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"exports/temp-b'1509431920'/saved_model.pb\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'exports/1509431920'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n",
    "export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "estimator.export_savedmodel('exports', export_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction w/Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the server docker image. Will include outputs from export above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!docker build -t movie-rating-tfserving ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the docker image and expose `localhost:8500` for the grpc server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!docker run --rm -d -p 8500:8500 movie-rating-tfserving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the python grpc client if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serving_src_root = os.path.expanduser('~/developer/serving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python3 -m grpc_tools.protoc -I{serving_src_root} -I{serving_src_root}/tensorflow --python_out={os.getcwd()} --grpc_python_out={os.getcwd()} {serving_src_root}/tensorflow_serving/apis/*.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from grpc.beta import implementations\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "from tensorflow_serving.apis import get_model_metadata_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "channel = implementations.insecure_channel('localhost', int(8500))\n",
    "stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_request(userId:int, movieId:int):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = 'default'\n",
    "    request.model_spec.signature_name = 'serving_default'\n",
    "\n",
    "    feature_dict = {\n",
    "        'userId': _int_feature(userId),\n",
    "        'movieId': _int_feature(movieId)\n",
    "    }\n",
    "    label = 0\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    serialized = example.SerializeToString()\n",
    "\n",
    "    request.inputs['inputs'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(serialized, shape=[1]))\n",
    "\n",
    "    result_future = stub.Predict.future(request, 5.0)\n",
    "    prediction = result_future.result()\n",
    "\n",
    "    predicted_rating = prediction.outputs[\"outputs\"].float_val[0]\n",
    "    actual_rating = ratings[(ratings['userId'] == userId) & (ratings['movieId'] == movieId)]['rating'][0]\n",
    "    print(f'Predicted value: {predicted_rating} vs actual {actual_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 2.4376325607299805 vs actual 2.5\n",
      "CPU times: user 4.47 ms, sys: 1.57 ms, total: 6.04 ms\n",
      "Wall time: 5.39 ms\n"
     ]
    }
   ],
   "source": [
    "%time make_request(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
