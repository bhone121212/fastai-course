{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = os.path.expanduser('~/data/fastai/lesson4')\n",
    "model_path = '/tmp/fastai/lesson4'\n",
    "\n",
    "if not os.path.isdir(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "if not os.path.isdir(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    \n",
    "movielens_folder = os.path.join(data_directory, 'ml-latest-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset if we don't have it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fallback_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "if not os.path.isdir(movielens_folder):\n",
    "    local_zip_path = os.path.join(data_directory, os.path.basename(fallback_url))\n",
    "    if not os.path.isfile(local_zip_path):\n",
    "        # Download zip file\n",
    "        urllib.request.urlretrieve(fallback_url, local_zip_path)\n",
    "    # Unzip file\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as z:\n",
    "        z.extractall(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1       31     2.5\n",
       "1       1     1029     3.0\n",
       "2       1     1061     3.0\n",
       "3       1     1129     2.0\n",
       "4       1     1172     4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_path = os.path.join(movielens_folder, 'ratings.csv')\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "ratings = ratings.drop(['timestamp'], axis=1)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_path = os.path.join(movielens_folder, 'movies.csv')\n",
    "movie_names = pd.read_csv(movies_path, index_col='movieId')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = ratings['userId'].unique()\n",
    "movies = ratings['movieId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid2idx = { userId: index for index, userId in enumerate(users) }\n",
    "movieid2idx = { movieId: index for index, movieId in enumerate(movies) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: write index to user and movie label metadata to model folder for tensorboard to use and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update movie and user Ids in ratings to be the index so we have a contiguous integer range for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings['userId'] = ratings['userId'].apply(userid2idx.get)\n",
    "ratings['movieId'] = ratings['movieId'].apply(movieid2idx.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        0     2.5\n",
       "1       0        1     3.0\n",
       "2       0        2     3.0\n",
       "3       0        3     2.0\n",
       "4       0        4     4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0-rc1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ratings[['userId', 'movieId']]\n",
    "y = ratings['rating']\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(x, y=y, target_column='rating', shuffle=True, num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=tf.feature_column.categorical_column_with_identity('userId', num_buckets=len(users), default_value=0), \n",
    "    dimension=50)\n",
    "movie_embedding = tf.feature_column.embedding_column(\n",
    "    categorical_column=tf.feature_column.categorical_column_with_identity('movieId', num_buckets=len(movies), default_value=0), \n",
    "    dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/fastai/lesson4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10a5f4978>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [user_embedding, movie_embedding]\n",
    "estimator = tf.estimator.DNNRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[70], \n",
    "    dropout=0.75,\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\n",
    "    model_dir=model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/fastai/lesson4/model.ckpt.\n",
      "INFO:tensorflow:loss = 1867.53, step = 1\n",
      "INFO:tensorflow:global_step/sec: 228.592\n",
      "INFO:tensorflow:loss = 840.253, step = 101 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.857\n",
      "INFO:tensorflow:loss = 313.73, step = 201 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.427\n",
      "INFO:tensorflow:loss = 282.478, step = 301 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.557\n",
      "INFO:tensorflow:loss = 231.264, step = 401 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.165\n",
      "INFO:tensorflow:loss = 299.091, step = 501 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.103\n",
      "INFO:tensorflow:loss = 321.18, step = 601 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.07\n",
      "INFO:tensorflow:loss = 261.147, step = 701 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.649\n",
      "INFO:tensorflow:loss = 415.107, step = 801 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.756\n",
      "INFO:tensorflow:loss = 228.497, step = 901 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.135\n",
      "INFO:tensorflow:loss = 262.498, step = 1001 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.532\n",
      "INFO:tensorflow:loss = 222.326, step = 1101 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.016\n",
      "INFO:tensorflow:loss = 142.092, step = 1201 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.417\n",
      "INFO:tensorflow:loss = 205.159, step = 1301 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.808\n",
      "INFO:tensorflow:loss = 173.908, step = 1401 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.287\n",
      "INFO:tensorflow:loss = 141.864, step = 1501 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.137\n",
      "INFO:tensorflow:loss = 214.944, step = 1601 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.139\n",
      "INFO:tensorflow:loss = 198.575, step = 1701 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.209\n",
      "INFO:tensorflow:loss = 139.543, step = 1801 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.329\n",
      "INFO:tensorflow:loss = 164.718, step = 1901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.388\n",
      "INFO:tensorflow:loss = 170.116, step = 2001 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.016\n",
      "INFO:tensorflow:loss = 152.621, step = 2101 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.264\n",
      "INFO:tensorflow:loss = 169.085, step = 2201 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.156\n",
      "INFO:tensorflow:loss = 144.159, step = 2301 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.252\n",
      "INFO:tensorflow:loss = 233.242, step = 2401 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.327\n",
      "INFO:tensorflow:loss = 185.436, step = 2501 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.5\n",
      "INFO:tensorflow:loss = 197.776, step = 2601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.67\n",
      "INFO:tensorflow:loss = 188.111, step = 2701 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.65\n",
      "INFO:tensorflow:loss = 134.945, step = 2801 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.822\n",
      "INFO:tensorflow:loss = 173.585, step = 2901 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.656\n",
      "INFO:tensorflow:loss = 146.555, step = 3001 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.968\n",
      "INFO:tensorflow:loss = 125.033, step = 3101 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.704\n",
      "INFO:tensorflow:loss = 169.205, step = 3201 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.154\n",
      "INFO:tensorflow:loss = 120.888, step = 3301 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.041\n",
      "INFO:tensorflow:loss = 128.438, step = 3401 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.832\n",
      "INFO:tensorflow:loss = 120.242, step = 3501 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.083\n",
      "INFO:tensorflow:loss = 124.285, step = 3601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.736\n",
      "INFO:tensorflow:loss = 159.486, step = 3701 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.118\n",
      "INFO:tensorflow:loss = 136.908, step = 3801 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.924\n",
      "INFO:tensorflow:loss = 122.786, step = 3901 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.177\n",
      "INFO:tensorflow:loss = 101.304, step = 4001 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.849\n",
      "INFO:tensorflow:loss = 131.022, step = 4101 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.824\n",
      "INFO:tensorflow:loss = 159.469, step = 4201 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.676\n",
      "INFO:tensorflow:loss = 110.336, step = 4301 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.078\n",
      "INFO:tensorflow:loss = 118.173, step = 4401 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.117\n",
      "INFO:tensorflow:loss = 117.519, step = 4501 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.364\n",
      "INFO:tensorflow:loss = 100.612, step = 4601 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.215\n",
      "INFO:tensorflow:loss = 135.248, step = 4701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.866\n",
      "INFO:tensorflow:loss = 130.821, step = 4801 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.588\n",
      "INFO:tensorflow:loss = 158.97, step = 4901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.603\n",
      "INFO:tensorflow:loss = 113.081, step = 5001 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.826\n",
      "INFO:tensorflow:loss = 105.658, step = 5101 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.1\n",
      "INFO:tensorflow:loss = 96.4448, step = 5201 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.36\n",
      "INFO:tensorflow:loss = 83.7484, step = 5301 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.105\n",
      "INFO:tensorflow:loss = 44.9726, step = 5401 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.661\n",
      "INFO:tensorflow:loss = 82.9958, step = 5501 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.015\n",
      "INFO:tensorflow:loss = 112.643, step = 5601 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.103\n",
      "INFO:tensorflow:loss = 108.606, step = 5701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.742\n",
      "INFO:tensorflow:loss = 126.442, step = 5801 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.152\n",
      "INFO:tensorflow:loss = 88.498, step = 5901 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.295\n",
      "INFO:tensorflow:loss = 94.9339, step = 6001 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.44\n",
      "INFO:tensorflow:loss = 112.432, step = 6101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.463\n",
      "INFO:tensorflow:loss = 93.8342, step = 6201 (0.357 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6251 into /tmp/fastai/lesson4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.5688.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x116b8df60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-10-31-02:25:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/fastai/lesson4/model.ckpt-6251\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-31-02:25:23\n",
      "INFO:tensorflow:Saving dict for global step 6251: average_loss = 0.664216, global_step = 6251, loss = 85.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 0.66421634, 'global_step': 6251, 'loss': 85.009491}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x, y=y, target_column='rating', shuffle=False, num_epochs=1)\n",
    "estimator.evaluate(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/fastai/lesson4/model.ckpt-6251\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"exports/temp-b'1509419744'/saved_model.pb\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'exports/1509419744'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n",
    "export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "estimator.export_savedmodel('exports', export_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction w/Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the server docker image. Will include outputs from export above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!docker build -t movie-rating-tfserving ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the docker image and expose `localhost:8500` for the grpc server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!docker run --rm -d -p 8500:8500 movie-rating-tfserving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the python grpc client if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_src_root = os.path.expanduser('~/developer/serving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m grpc_tools.protoc -I{serving_src_root} -I{serving_src_root}/tensorflow --python_out={os.getcwd()} --grpc_python_out={os.getcwd()} {serving_src_root}/tensorflow_serving/apis/*.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from grpc.beta import implementations\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "from tensorflow_serving.apis import get_model_metadata_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "channel = implementations.insecure_channel('localhost', int(8500))\n",
    "stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_request(userId:int, movieId:int):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = 'default'\n",
    "    request.model_spec.signature_name = 'serving_default'\n",
    "\n",
    "    feature_dict = {\n",
    "        'userId': _int_feature(userId),\n",
    "        'movieId': _int_feature(movieId)\n",
    "    }\n",
    "    label = 0\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    serialized = example.SerializeToString()\n",
    "\n",
    "    request.inputs['inputs'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(serialized, shape=[1]))\n",
    "\n",
    "    result_future = stub.Predict.future(request, 5.0)\n",
    "    prediction = result_future.result()\n",
    "\n",
    "    predicted_rating = prediction.outputs[\"outputs\"].float_val[0]\n",
    "    actual_rating = ratings[(ratings['userId'] == userId) & (ratings['movieId'] == movieId)]['rating'][0]\n",
    "    print(f'Predicted value: {predicted_rating} vs actual {actual_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 2.4376325607299805 vs actual 2.5\n"
     ]
    }
   ],
   "source": [
    "make_request(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
